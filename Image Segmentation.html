<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol.lst-kix_cp2muz16jvan-4.start{counter-reset:lst-ctn-kix_cp2muz16jvan-4 0}ol.lst-kix_cp2muz16jvan-2.start{counter-reset:lst-ctn-kix_cp2muz16jvan-2 0}ol.lst-kix_cp2muz16jvan-7.start{counter-reset:lst-ctn-kix_cp2muz16jvan-7 0}.lst-kix_cp2muz16jvan-4>li:before{content:"(" counter(lst-ctn-kix_cp2muz16jvan-4,lower-latin) ") "}.lst-kix_cp2muz16jvan-3>li:before{content:"(" counter(lst-ctn-kix_cp2muz16jvan-3,decimal) ") "}.lst-kix_cp2muz16jvan-2>li{counter-increment:lst-ctn-kix_cp2muz16jvan-2}.lst-kix_cp2muz16jvan-1>li:before{content:"" counter(lst-ctn-kix_cp2muz16jvan-1,lower-latin) ") "}.lst-kix_cp2muz16jvan-5>li{counter-increment:lst-ctn-kix_cp2muz16jvan-5}.lst-kix_cp2muz16jvan-2>li:before{content:"" counter(lst-ctn-kix_cp2muz16jvan-2,lower-roman) ") "}ol.lst-kix_cp2muz16jvan-5.start{counter-reset:lst-ctn-kix_cp2muz16jvan-5 0}ol.lst-kix_cp2muz16jvan-8.start{counter-reset:lst-ctn-kix_cp2muz16jvan-8 0}.lst-kix_cp2muz16jvan-8>li{counter-increment:lst-ctn-kix_cp2muz16jvan-8}.lst-kix_cp2muz16jvan-0>li:before{content:"" counter(lst-ctn-kix_cp2muz16jvan-0,decimal) ") "}ol.lst-kix_cp2muz16jvan-0.start{counter-reset:lst-ctn-kix_cp2muz16jvan-0 0}.lst-kix_cp2muz16jvan-7>li{counter-increment:lst-ctn-kix_cp2muz16jvan-7}ol.lst-kix_cp2muz16jvan-3.start{counter-reset:lst-ctn-kix_cp2muz16jvan-3 0}ol.lst-kix_cp2muz16jvan-8{list-style-type:none}.lst-kix_cp2muz16jvan-1>li{counter-increment:lst-ctn-kix_cp2muz16jvan-1}ol.lst-kix_cp2muz16jvan-6{list-style-type:none}ol.lst-kix_cp2muz16jvan-7{list-style-type:none}ol.lst-kix_cp2muz16jvan-4{list-style-type:none}ol.lst-kix_cp2muz16jvan-5{list-style-type:none}ol.lst-kix_cp2muz16jvan-2{list-style-type:none}ol.lst-kix_cp2muz16jvan-3{list-style-type:none}ol.lst-kix_cp2muz16jvan-0{list-style-type:none}ol.lst-kix_cp2muz16jvan-1{list-style-type:none}.lst-kix_cp2muz16jvan-4>li{counter-increment:lst-ctn-kix_cp2muz16jvan-4}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ol.lst-kix_cp2muz16jvan-6.start{counter-reset:lst-ctn-kix_cp2muz16jvan-6 0}.lst-kix_cp2muz16jvan-5>li:before{content:"(" counter(lst-ctn-kix_cp2muz16jvan-5,lower-roman) ") "}ol.lst-kix_cp2muz16jvan-1.start{counter-reset:lst-ctn-kix_cp2muz16jvan-1 0}.lst-kix_cp2muz16jvan-6>li:before{content:"" counter(lst-ctn-kix_cp2muz16jvan-6,decimal) ". "}.lst-kix_cp2muz16jvan-3>li{counter-increment:lst-ctn-kix_cp2muz16jvan-3}.lst-kix_cp2muz16jvan-7>li:before{content:"" counter(lst-ctn-kix_cp2muz16jvan-7,lower-latin) ". "}.lst-kix_cp2muz16jvan-6>li{counter-increment:lst-ctn-kix_cp2muz16jvan-6}.lst-kix_cp2muz16jvan-0>li{counter-increment:lst-ctn-kix_cp2muz16jvan-0}.lst-kix_cp2muz16jvan-8>li:before{content:"" counter(lst-ctn-kix_cp2muz16jvan-8,lower-roman) ". "}ol{margin:0;padding:0}table td,table th{padding:0}.c14{-webkit-text-decoration-skip:none;color:#292929;font-weight:700;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:20pt;font-family:"Arial";font-style:normal}.c5{-webkit-text-decoration-skip:none;color:#292929;font-weight:700;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:16.5pt;font-family:"Arial";font-style:normal}.c8{background-color:#ffffff;padding-top:0pt;padding-bottom:-7pt;line-height:1.15;orphans:2;widows:2;text-align:justify;height:11pt}.c10{background-color:#ffffff;padding-top:13pt;padding-bottom:-7pt;line-height:2.1818181818181817;orphans:2;widows:2;text-align:justify;height:11pt}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c3{background-color:#ffffff;padding-top:13pt;padding-bottom:-7pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c11{background-color:#ffffff;padding-top:0pt;padding-bottom:10pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c24{padding-top:0pt;padding-bottom:-9pt;line-height:0.9130434782608695;orphans:2;widows:2;text-align:left}.c13{padding-top:30pt;padding-bottom:-7pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c17{padding-top:0pt;padding-bottom:-7pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c18{-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline;text-decoration-skip-ink:none;font-size:12pt;font-style:italic}.c9{background-color:#ffffff;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c25{padding-top:72pt;padding-bottom:-9pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c27{font-weight:700;text-decoration:none;vertical-align:baseline;font-family:"Georgia";font-style:normal}.c23{text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c2{background-color:#ffffff;font-size:12pt;color:#292929;font-weight:700}.c22{font-size:16.5pt;color:#292929;font-weight:700}.c4{font-size:12pt;color:#292929;font-weight:700}.c6{background-color:#ffffff;font-size:15pt;color:#292929}.c28{color:#292929;font-weight:700;font-size:12.5pt}.c26{max-width:468pt;padding:72pt 72pt 72pt 72pt}.c7{color:#292929;font-size:12pt}.c16{color:#292929;font-size:15pt}.c20{padding:0;margin:0}.c21{color:inherit;text-decoration:inherit}.c29{color:#757575;font-size:10.5pt}.c15{margin-left:36pt;padding-left:0pt}.c12{background-color:#ffffff}.c19{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c12 c26 doc-content"><h1 class="c12 c24" id="h.t6i9zhue52yw"><span class="c22">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c14">Semantic Segmentation</span></h1><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><h1 class="c24 c12" id="h.pdrjy7jlfk5o"><span class="c5">Introduction</span></h1><p class="c3"><span class="c4">Computer vision</span><span class="c7">&nbsp;is an interdisciplinary scientific field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human v</span><span class="c7 c12">isual system can do. Deep Learning has enabled the field of Computer Vision to advance rapidly in the last few years. In this post I would like to discuss one specific task in Computer Vision called </span><span class="c2">Semantic Segmentation</span><span class="c7 c12">. Even though researchers have come up with numerous ways to solve this problem, I will talk about a particular architecture namely </span><span class="c2">UNET</span><span class="c7 c12">, which uses a Fully Convolutional Network Model for the task. We will use UNET to build a first-cut solution to the </span><span class="c12 c18"><a class="c21" href="https://www.google.com/url?q=https://www.kaggle.com/c/tgs-salt-identification-challenge&amp;sa=D&amp;source=editors&amp;ust=1659635657389736&amp;usg=AOvVaw3UOP2yibtrn5JnamkU36wK">TGS Salt Identification</a></span><span class="c9 c7">&nbsp;challenge hosted by Kaggle.</span></p><p class="c8"><span class="c9 c7"></span></p><h1 class="c11" id="h.9zgmnnxxm2vp"><span class="c5 c12">Prerequisites</span></h1><h1 class="c11" id="h.1ucy5h2sj66"><span class="c9 c7">I will assume that the reader is already familiar with the basic concepts of Machine Learning and Convolutional Networks. Also you must have some working knowledge of ConvNets with Python and Keras library.</span></h1><p class="c8"><span class="c9 c7"></span></p><p class="c17 c12"><span class="c5 c12">What is Semantic Segmentation?</span></p><p class="c8"><span class="c23 c12 c28"></span></p><p class="c17 c12"><span class="c9 c7">The goal of semantic image segmentation is to label each pixel of an image with a corresponding class of what is being represented. Because we&rsquo;re predicting for every pixel in the image, this task is commonly referred to as dense prediction.</span></p><p class="c3 c19"><span class="c9 c16"></span></p><p class="c3"><span class="c6">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 349.37px; height: 158.20px;"><img alt="" src="images/image1.png" style="width: 349.37px; height: 158.20px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c9 c29">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></p><h1 class="c12 c25" id="h.85z7rdeke5v"><span class="c5 c12">Applications</span></h1><p class="c1"><span class="c0"></span></p><p class="c17 c12"><span class="c9 c7">If you are wondering whether semantic segmentation is even useful or not, your query is reasonable. However, it turns out that a lot of complex tasks in Vision require this fine grained understanding of images.</span></p><p class="c3"><span class="c9 c7">For example:</span></p><ol class="c20 lst-kix_cp2muz16jvan-0 start" start="1"><li class="c3 c15 li-bullet-0"><span class="c9 c7">Autonomous Vehicles</span></li><li class="c3 c15 li-bullet-0"><span class="c9 c7">BioMedical Image Diagnosis</span></li><li class="c3 c15 li-bullet-0"><span class="c9 c7">Geo sensing</span></li><li class="c3 c15 li-bullet-0"><span class="c9 c7">Precision Agriculture</span></li></ol><p class="c3"><span class="c5 c12">Business Problem</span></p><p class="c8"><span class="c2 c23"></span></p><p class="c12 c17"><span class="c18 c12"><a class="c21" href="https://www.google.com/url?q=https://www.tgs.com/&amp;sa=D&amp;source=editors&amp;ust=1659635657393088&amp;usg=AOvVaw1gnGt11_EK-CXdASPKsal5">TGS </a></span><span class="c9 c7">is one of the leading Geo-science and Data companies which uses seismic images and 3D renderings to understand which areas beneath the Earth&rsquo;s surface contain large amounts of oil and gas.</span></p><p class="c12 c13"><span class="c7 c12">Interestingly, the surfaces which contain oil and gas, also contain huge deposits of salt. So with the help of </span><span class="c2">seismic </span><span class="c7 c12">technology, they try to predict which areas on the surface of the Earth contain huge amounts of </span><span class="c2">salts</span><span class="c9 c7">.</span></p><p class="c13 c12"><span class="c7 c12">Unfortunately, professional seismic imaging requires expert </span><span class="c2">human vision</span><span class="c7 c9">&nbsp;to exactly identify salt bodies. This leads to highly subjective and variable renderings. Moreover it could cause huge losses for the oil and gas company drillers if the human prediction is incorrect.</span></p><p class="c13 c12"><span class="c7 c12">Thus TGS hosted a Kaggle Competition, to employ </span><span class="c2">machine vision</span><span class="c9 c7">&nbsp;to solve this task with better efficiency and accuracy.</span></p><p class="c3 c19"><span class="c9 c7"></span></p><p class="c3 c19"><span class="c9 c7"></span></p><p class="c10"><span class="c6 c27"></span></p><p class="c1"><span class="c0"></span></p></body></html>